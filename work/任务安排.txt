////////////////

全部执行 和分开执行都实现 分配跑2个

存力并发方案重新按如下思路分析：
1. 管软分发，以目录切分任务，明确具体的目录名路径等信息，不同节点backend扫描各自的目录，实现并发执行任务，支持多种策略：hash/轮询，其中hash说清楚根据什么hash；管软负责创建（生产者），目录负责存储（队列），backend定时消费；不需要管软通过命令通知到backend执行任务；
2.并发的核心问题是同一个文件并发迁移如何处理，1）文件迁移状态机，MDS加元数据控制；2）迁移失败不回滚，添加到失败任务文件再进行回滚；
3.高可用：基于1策略，不需要支持失败的backend将其任务分发给其他backend，backend何时起来何时重新扫描目录，backend当前有monitor自监控脚本，如果停了会自动拉起；
4.升级，如果按节点切分目录后，如何实现当前存力的升级？人为处理说明都行，比如等当前正在执行的都处理完，离线升级等等；
5.无需考虑自迁移，自迁移和这套思路不冲突；

第三次评审总结
1. 概要设计页数4-5页， 这个提示多次 从50M到120页 到30页，不自觉的 增加起来。
 这个情况自觉一定主要，一定是4到5页 【别人根本精力和时间看这个】 
 
 ---写太多，没有给出 什么场景，什么场景， 如何解决的，如何解决的。
 
 
 字体 截图 不统一 代码 
2. kafa故障，长连接故障，s3故障这样你不应该写--写时候犹豫了一下 最后填写的[和并发没有关系]
3. 你感觉 新增tick线程处理，tick周期结果 还是不行【实现上很难，感觉对对】
4. 自己的自测结果， 分析过程 写上不对【自己想清楚不写，暴露什么问题】
5.  按照思路 保证1000%正确吗？

----给谁看的----------

问题发生原因
引发什么场景问题
引发什么场景问题

----什么情况需要回顾 什么情况不需要回顾 这个说清楚。

怎么解决的，

那些解决不了问题是什么
同一个文件：
2个节点并发迁移，间隔时间短，
第一个失败回滚，第二个成功

第一个：
在setxattr执行过程过
第二个：开始迁移

无item_open_list占用
对xlock竞争，

--------------------------------------

在最后一个对象后，
重复释放caps core

多个节点并发情况
1. 成功，成功
2. 失败，成功 
3. 成功，失败 
4. 失败，失败 


任务状态记录inode中，
2个线程更新同一个地址。


2个方式
1.当文件被创建，删除时候 mds主动上报
2. 对账方式

这2个方式都没有统计文件访问次数。


2个节点并发迁移，间隔时间长
第一个：在setxattr执行过程过
第二个：开始迁移
第一个成功，第二个失败

第一个：在setxattr执行过程过，
第二个：在读写




存力并发方案重新按如下思路分析：
1. 管软分发，以目录切分任务，明确具体的目录名路径等信息，不同节点backend扫描各自的目录，实现并发执行任务，支持多种策略：hash/轮询，其中hash说清楚根据什么hash；管软负责创建（生产者），目录负责存储（队列），backend定时消费；不需要管软通过命令通知到backend执行任务；


2.并发的核心问题是同一个文件并发迁移如何处理，1）文件迁移状态机，MDS加元数据控制；2）迁移失败不回滚，添加到失败任务文件再进行回滚；


3.高可用：基于1策略，不需要支持失败的backend将其任务分发给其他backend，backend何时起来何时重新扫描目录，backend当前有monitor自监控脚本，如果停了会自动拉起；
4.升级，如果按节点切分目录后，如何实现当前存力的升级？人为处理说明都行，比如等当前正在执行的都处理完，离线升级等等；
5.无需考虑自迁移，自迁移和这套思路不冲突

////////////////////////////////////////



评审意见：
原因：
场景：【无法区分场景】
解决方式：
约束限制
无法解决问题
5页
高可用

格式 格式


-------
1. 自己推导到分析过程太多 隐藏问题。
   和解决不了方案。

2. 并发问题没有解决，发散到其他点子上。
其他无法内容不听写



方案能解决100%问题吗？

---------------------------





原因：这个


情况无法区分是单个文件单节点迁移，

并发迁移过程失败处理方案

1. 直接回滚，上报结果，让存力平台判断重试还是不重试
   适用条件：明确的错误
    1.write: 配置错误
	2. setxattr：文件大小被修改,文件不存在
	
   不能解决并发场景：一个成功，一个失败
   1. write阶段：远端集群s3 网络故障失败
   2. setxattr阶段 同一个文件被多个节点迁移
   原因：这个情况无法区分是单个文件单节点迁移，还是多节点迁移？
   
   优化方式
   1. 避免方式：接口失败，然后重试1次，减少s3服务重启，网络等故障影响。
   2. 重试后依然可能失败情况--见原因

2。针对具体错误码延迟回滚,其他直接回滚.
   方式1:元数据只记录文件是最终迁移结果--不可取
    根据元数据是否迁移完成,判断是否回滚,判断不准确
	不支持场景 存力重试 和迁移回滚冲突.
   
   方式2:元数据记录整个任务迁移状态,
   1. 在setxattr查询 ,如果不是setxattr阶段 说明有其他处理情况-直接返回具体错误
   2. 在write阶段查询,无法区分是当前write 还是其他阶段write--无法区分 
   3. 节点重启后,在重新迁移场景不好区分
   
3. 针对具体错误,不回滚重试
 新的影响:
  1 重试 也可能是失败,远端还是存在无法回滚文件.对比之前直回滚,增加新的影响
   
   



-----------------------------------------------------------------
rust-analyzer

1. 单节点执行时候 local不可用
2. 多节点处理

1. 当前任务分配失败
2. 部分文件迁移失败


1 目录隔离情况 不考虑
方法1：管软不负责任务发送，交给高可用节点。
完成任务


1. 元数据检索
2. 

不清楚项目方案是什么投入多次时间完成

通过开一次会议清楚方案是什么，投入多次时间完成
需要做那些事情？
1. 各种方案优缺点怎么分析
2. 全面分析各种情况

1. 挂载点不可用，写文件阻塞。
2. 自测出现，fuse读取任务core
   引发backend重启，加载历史任务迁移退出。
   
   
   



每次任务分配判断Backend健康状态
1. 增加集群负担
2. 这个情况是否模糊


任务分配后无迁移

1. 不进行重试
2. 目录隔离的直接放到各自目录。
3. 

1. 目录隔离方式，通知Backend失败情况不进程重试
2. 
1. 节点故障
2.  节点正常，迁移进程Backend异常

目录隔离方式分配，不进程重试
1. 按照分配方式任务移动目录
2. 不考虑backend是否接受任务情况

通知mds rank0 方式增加重试。



1.管理网卡，pulic网卡ifdown
2. kill管软故障
3.reboot

1 高可用方案设计
2 多节点方案设计
3.代码开发实现。


1. 分析各种故障类型，全面考虑异常。
2. 每个方案给出优缺点。
3. 代码开发。

昨天人员不够并没有对整个方案进行评审
只是针对3个故障类型进行讨论
1. 存力重试情况 章节2.1 满足 存力超时重试情况下，完成剩余文件迁移
2. 服务故障恢复后无法恢复情况 2.4.4。采取处理方案
3. 发送任务时候 服务节点异常处理 是否考虑节点是否存在。
4. 并没有对通过mds等其他存储进行详细讨论

下一步计划
1. 调查一下支持重复迁移可行性。
2. 完善并发思路和优缺点和不同故障处理。
避免方式
1. icfs dump 判断集群是否可用
2. 查询可用节点，不保证backend服务可用。

3.
1.管理网卡，pulic网卡ifdown
2. 管软故障 
避免方式
1. 管软产生任务完成时候rename任务
2. http引入去中心化token机制
   防止重复请求

1. icfs dump 判断集群是否可用
2. 查询可用节点，不保证backend服务可用。
3. 

1. 避免方式 迁移时候 单节点查重，
   多节点不支持
2. 支持重复迁移


管软重试，
同一个任务分配不同节点。
造成数据丢失
2 集群切,数据一 /mnt/fuse、

1. 挂载点短暂不可访问
2. 开发阶段：挂载点不可用
  需要手工重启nfs 
  或者手工删除历史任务


自测出现
nfs造创建一个文件，fuse读取失败
重复执行这个任务。
或者backend重启迁移任务

挂载点短暂不可用
或者永远不可用，
需要手工删除异常任务

1. 集群切换 /mnt/fuse 挂点不可用
2. gpair配置别修改
3. 自测出现代码问题
   
   
1.管理网卡，pulic网卡ifdown
2. 部分管软故障，reboot
 
 
 











 


   




1. 任务 占用内存评估
2. 管软与Backend 不与Backend 连接
   2者没有关系

1. MDS 周期性执行，根据umcomple表 撤销没有处理任务
2.  Backend与MDS之间有连接。针对不同故障情况有做判断。

1. 分级迁移内部的速度比跨域快
   
   
   


判断文件执行超时，文件积压数量 


1. 后台线程，增加管软负担
2.  判断一个服务不可用 通过进程 网络 节点存 超时 判断文件是否 方式 判断 过于复杂

1 增加ctdb 负担，影响更多业务
2. 同上
3. 增加一个服务，维护服务本身高可用



. 后台线程，增加管软负担
2.  判断一个服务不可用 通过进程 网络 节点存在方式比较复杂


1. 任务重新分配放到Backend完成，需要总线节点 保证Baackend 高可用

1. Backend不对外提供服务，让管软，ctdb提供虚拟ip 方式可是

1. 通过vip节点方式接受任务 单点
   Backend不对外提供服务，让管软，ctdb提供虚拟ip 不合适

2. 通过域名方式方式接受任务。Baackend是正常

1. 单独增加一个服务
2. 该服务可靠性自身保证形成单点
3.tick设置过大， mon 切换 ，都任务是主造成冲突 （引发）


1. 增加ctdb 负担，影响更多业务

1 .分配任务 处理任务 
2. 完成任务汇报状态 例如管软的中间件
3. 让管软监控任务状态，非判断进程 +目录文件积压方式








1. 每个Backend接受任务 支持
2. 撤回 选择一个节点执行


管软故障：
步骤1：临时任务不迁移，存力平台重试无影响
步骤2：
步骤3：
文件迁移，存力重试有并发问题
 
1. 不包含负载业务，可用通过脚本自动拉起监控
2. 让ctdb 保证节点和网络中正常

1 ctdb 保证 主节点 节点 和网络正常
2. 
1. 发送任务和撤销任务放被Keepalived 管统一管理
2. 避免管软通知期服务那个是最新节点。

1. 进程 不包含负载业务，故障后自动起来 自动拉起监控
2.  ctdb 保证节点 和网络正常。

1. 单独增加一个服务
2.该服务可靠性自身保证。不让ctdb接管。
形成单点
3. 不想s3 这个负载问题到用着管理







同一个节点负载高


负载高，
撤回部分任务，有重新分配回来。
参数控制
1. 设置合适的积压任务阈值
2. 调整回收任务个数n和分配任务m大小



backend重启加载和回收线程冲突
1. 回收线程设置[1backend,2backend]
2. 在回收之前在判断一次backend存活



1. 任务发送:移动对应目录，不考虑backend通知是否成功
2. 任务发送: 根据时间排序，连接5任务发同一个节点/随机
3. 任务处理：目录隔离无冲突。
4. 分配任务tick周期5秒，任务回收线程tick 80秒一次，不冲突


1. 轮询分配，根据时间排序，最近5个任务发送同一个节点
2. 调整tick周期，避免发送和回收任务线程冲突
3. 任务处理：目录隔离并发冲突



1.只要任务引入对应目录
 不考虑
 
任务发送:
1. 任务发送: 
  不考虑通知Backend 网络故障 和服务故障识别问题
  有回收任务线程处理
  
1.移入二级目录会后
2.不考虑通知Backend失败问题。



  
  

 
 

存力平台无限重试
同一批文件产生不同任务


1. 管软写临时任务故障--存力重试
2. rename后，管软故障不考虑




1. 不支持同一个文件被重复迁移
2. 不记录文件迁移过程。



1. 其其他线程在处理同一个文件无冲突
2. 兼顾 发送Kafa失败，迁移失败的文件


1. 任务发送:移动对应目录，不考虑backend通知是否成功
2. 任务发送: 根据时间排序，最近n个记录发送同一节查重。
2. 任务处理：目录隔离无冲突。
3. 分发tick周期5秒，任务回收线程tick 80秒一次，不冲突

  
1. 与任务发送线程无冲突
2. 与Backend任务执行无冲突
3. 与任务回收线程无冲突

1. Backend迁移无冲突 2 其他2个线程无冲突

1. 与其他2个线程无冲突
2. 与Backend无冲突
3. 与管软故障无冲突


1. 任务发送:移动对应目录,只通知backend一次不重试
2. 任务处理：目录隔离无冲突。

1. 任务发送:移动对应目录，不考虑backend通知是否成功
2. 任务处理：目录隔离无冲突。
3. 分发tick周期5秒，任务回收线程tick 80秒一次 不冲突


1 与s3长连接初始化建立好，不选择其他可用节点
2. setxattr不支持同一任务被重复处理
3. 迁移过程无法上报

】
1. 目录隔离backend处理无冲突
2. tick周期不一样，与回收线程无冲突12

1. tick周期不一样，与其他线程无冲突
2. 只要移入对应目录，发送命令失败不迁移其他节点， Backend直接处理冲突
3. Backend直接处理冲突

1. 分发


1. 迁移：目录隔离backend处理无冲突
2. 分发
1. 任务重新处理
2. 任务积压线程处理

1. 通过目录和限制同时执行隔离 解决重复处理问题
2. 一个任务可用在单节点重复执行。
3. 任务积压检测线程 撤回任务。


1. 通知kafa迁移结果可能多/少
2. s3 提供偏移量迁移，不解决
  偏移量之外文件变化。


1 与s3长连接初始化建立好，不选择其他可用节点
2. setxattr不支持同一任务被重复处理

1 与s3长连接初始化建立好，不选择其他可用节点
2. setxattr不支持同一任务被重复处理

1. s3确认是否心跳检测接口
2. 失败时针对错误码(待协商)重写连接其他节点
3. 执行过程数据丢

1. s3确认是否心跳检测接口
2. 失败时针对错误码(待协商)重写连接其他节点

3. 任务发送时候 根据时间排序 连续5个任务发送同一个节点
4. 不记录处理结果，只记录失败结果，等待下次处理。
 
 
 1. 多节点同时重复迁移
 2. 不存储迁移整个过程。

1. 目录隔离backend处理无冲突
2. tick周期不一样，与回收线程无冲突



1. 任务重新处理。还原中间结果
2. 任务积压线程处理

1. 通知Kafa记录

1.不记录中间结果，一个任务 500个文件，重新迁移。
2. 


打破信息差，把英文内容翻译中文
1. github最新热门项目，例如 ai各种开源工具
2. github开源产品背后设计理解，解决问题
3. 参考阮一峰的周刊，最近每周科技新闻

1. 经验分享：被面试官问的哑口无言(背后原理架构底层东西)
2. 经验分享：手撕红黑树

面试时候
1. 在线ide/白板手写2个算法，然后执行出结果
2. 系统设计绘制架构图，并3-5句话描述问题是什么

打破信息差，把英文内容翻译中文
1. github最新热门项目，例如 ai各种开源工具
2. github开源产品背后设计理解，解决问题
3. 参考阮一峰的周刊，最近每周科技新闻

看榜样怎么做的
1. 在外包，电信落后行业 
2. 最新行业发展：容器调度， 
3.创业公司人员：发明什么产品，解决什么问题

看榜样(非偶像)在做什么
1. 公司里厉害的人
2. 国内技术人分享
3. 国外技术人分享


本月
1. 稳定性: 
   1.1 完成丢文件和错误码原因定位。同一个问题，管软产生了重复请求，Backend迁移重复请求
   1.2 确定解决办法, Backend单节点排重，管软保证多个请求产生不同任务,
   1.3 放到多节点迁移一块实现。

2. 性能：
  2.1. 写速度移动统计完成，自测环境未完成。
  2.2  s3/lib不会优化，改为多节点并发迁移
  2.3  通过多节点迁移完成优化。

3 多节点迁移
 3.1 高可用设计 --无 
 3.3 多节点方案--无 
 ==============================================================
 
 
 1.高可用方案设计并评审通过
 2. 多节点方案设计并评审通过
 3. 功能实现

1. 迁移失败，回滚，然后存力重试
2.  迁移失败 延迟回回滚，回滚，然后存力重试

3 不回滚，自觉发起重试，存力发起重试


 
 ---------
1. 输出概要设计,并评审通过
2. 代码开发完成
3. 测试无bug


1. 概要设计，增加重试代替回滚方式 90%
2. 用虚拟机重新搭建一套环境
 
 setxattr 根据不同错误码不同处理
 1. 文件被修改---直接回滚
 2. 元数据被其他线程标记完成--- 迁移成功，不回滚
 3. 被占用情况---异步请求不重试，不回滚，文件重试
 4. 其他情况 同3
 

 
 
 

 
---------------------------------------
多节点任务
稳定性：
性能：
并发：
--------------------------------------------
1. 高可用方案实现20%，
   梳理解决问题是什么，绘制任务分发和执行流程图
2. 稳定性：重复文件迁移问题定位，
           已经通知管软修改，backend单节点查重处理
3. 配额测试支持。

任务状态
无分配
已经分配
转移其他节点任务


01--host1--ip1--process
02--host2--ip2--process
03--host3--ip3--process
..............
07--host7--ip7--process


1.阅读文件锁概要设计问，了解宽限期概念
2. 了解worm类型文件宽限期命令设置。 

keepalived

1. 新领导如何选举
2. 新的领导如何处理上个领导剩余热吻你
主要问题是：

管软:   任务分发
Backend：任务执行


将文件从一个集群迁移到另外一个集群。

存在什么问题

1.任务分配： 
   部分服务故障后，管软新分配任务/已经分配无法转移到可用节点上
   如果单个节点执行 服务不可用，多个节点，相关任务丢失。
2. 

期望结果：
1.任务不遗漏
2.迁移正确，




Backend 只负责任务执行，
在故障情况下，一个Backend故障了，请求发送到另外一个Backend上。
假设：新的Backend不去处理






-----------------------------------------
主要把移动存力 方案讨论清楚，能讨论一点是一点 
多讨论几次，吸纳其他人建议
多讨论几次，吸纳其他人建议。
讨论前提，综合考虑。

---------------------------------------------------------------
其他问题暂时不考虑一下。


好的，最后一周看能不能多投入一些，有困难的话跟立晓反馈下，让他跟移动再沟通沟通~~





curl -XPUT http://10.20.30.40:9200/_cluster/settings -d'
{
    "transient" : {
      "logger.discovery ": "WARN"
    }
}'

http://www.lvesu.com/blog/es/logging.html


http://www.lvesu.com/blog/es/logging.html



1. 丢数据问题确认管软在并发情况下遗漏任务。
2. 高可用方案设计10%，整理需求。


福布斯行为模型 提供方法 和原理，
怎么组合整出100个案例来，普通人可能需要这个。相互监督
你说出美好一天就具体

什么懒人，必须服务到家 提供方法，提供例子还不行，还是体验，监督 反馈







别的同学都睡觉你起床这么干什么，简直自欺欺人，你是整个班级，整个公司起床最晚那个人。


我30分钟床衣服


讨论结论：
1.文件内部并发采用现有的offset+len接口，不使用分片上传接口；
2.rename接口，S3实现目标目录不存在时创建；
3.采用每个迁移线程一个连接的方式，实现迁移对端多节点并发接收数据；
4.当前不实现多迁移任务并发，后面实测下迁移效果；




rename


3月产生并发迁移优化思路，4月份实现一篇。


1. 容易题不丢分，先吃小甜点+1分，增加学习动力
  std::move()实现原理 为什么
  为什么支持传入的是左值还是右值这2个参数是&&原因吗
  为什么返回的都是右值引用，是static_cast功劳吗？
  了解rust 用引用 生命周期用法
  完全是程序员思维。不管什么raft，什么rockdb，自己看不懂内容
  
  
  如果 T 是一个左值引用类型（如 int&），
  T&& 将折叠为 T&；
  如果 T 是一个右值引用类型（如 int&&），T&& 将折叠为 T。
  
  
  商家最终解释权，
  

从样板到最后实例化中间还有过程 
这个编译器发挥作用了



买家秀

1. 构思文件并发迁移专利内容，本月无实现，下月开始实现一篇，
2. 为专利专员讲解上个专利内容，完成节点审批。
s

1. Backend在重复迁移,ifdown网卡等情况出现放caps会core验证。

1. Backend什么情况出现迁移出现core验证
  s 单节点重复迁移查重处
2.

1.Backend在各种故障情况下服务是否core验证
 a:单节点重复迁导致重复释放caps
 b：gpair配置变动 
 c：ifdown网卡--出现过1次，待还原原因a
 
2.并发不一致原因分析
 有业务读写，client caps 没有调整want=-1情况
 导致setxattr失败
3. 2个实现方案对比
  方案1：元数据增加任务状态，判断不可用，
  方案2：根据错误码判断回滚不回滚改为重新迁移一次
4.整理HA方案

  
  
1.济南IT现场core问题跟踪
无法远程支持，在开发环境构造同样环境查看core文件
 快照为null断言，不能规避方式解决，
待实现：构造同样数据，还原core场景。

2. 机器上架