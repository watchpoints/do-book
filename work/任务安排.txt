通过过去工作经验

1. 过去经验可能跟存储没有关系，

工作能力：


1）对分布式文件系统原理尤其是mds需要提升
2）对其他文件系统产品(Lustre)优秀设计需要了解

1) 通过询问过去公司和工作经验 判断是否满足岗位最细需求

1) 通过咨询过去公司和s


1）通过询问过去公司和工作经验


1）通过询问过去公司和工作经验有一定经验
2）

1）

1）通过询问过去公司和工作经验 能匹配目前岗位。


在mds方面/文件系统方面，理解背后原理
 和吸纳其他产品设计优点。
 
增加核心理解

在mds方面/文件系统方面，理解背后原理
 和吸纳其他产品设计优点。

待掌握MDS的重要特性 和同类优秀产品


在文件系统方面，尤其是
MDS方面一些重要特性 和对比同类产品
和相关产品设计
 
 
过去工作经验和背景满


3）提高工作热情

提高工作热情

1）工作方式
 在mds方面/文件系统方面，理解背后原理
 和吸纳其他产品设计优点。
2）工作热情方面
文件系统学习有一定门槛，需要提高工作专注和热情。



过去经验没有持续设计
  




之前工作经验不能有效


1）需要人力支持
   移动存力项目计划截至10月底完成GFS剩余的功能。
   其中 水位自迁移，支持对等体读写，满足TR5系统稳定性测试功能
   
(3)态度：

(1) 掌握分布式系统原理，不仅仅了解业务，从业务抽象读写操作更了解背后原理。例如目录分片等
(2)平衡工作,家庭,生活等各方面关系，从长远角度考虑提高 工作提效，职业发展。



待提高：最终聚焦mds上，通过一个流程图或者4-5页解释清楚
抓住核心是什么，针对每个场景考虑清楚，如何解决的，解决方式是否考虑全面，是否还有其他方式代替和约束限制。

(2) 能力：有一定的借鉴其他产品设计思想，解决并发问题
     用重试方式 模拟最终一致性，解决分布式场景下部分失败，部分成功问题
	 
	 
	态度：
期间：元数据管理在性能提示/故障处理/特性程有挑战完成事情,愿意投入时间和精力完成
待提高：抓住重点：从期望完成什么，验收标准什么入手，围绕目标不断探索，不够迭戈沟通



态度：
为了解决问题尝试加班等方式，
因为日常小细节2次手机没电等忘记打卡，


(1) 

(3)态度：
期间：元数据管理在性能提示/故障处理/特性程有挑战完成事情,愿意投入时间和精力完成
待提高：抓住重点：从期望完成什么，验收标准什么入手，围绕目标不断探索，不够迭戈沟通



(1) 一定探索
为了解决问题积极协调管软，lib，对象不同模块。
待提高：最终聚焦mds上，通过一个流程图或者4-5页解释清楚
抓住核心是什么，针对每个场景考虑清楚，如何解决的，解决方式是否考虑全面，是否还有其他方式代替和约束限制

(2)能力：
用重试方式代替分布式

(1)工作业绩:GFS并发方案分析，完成迁移服务在不同故障场景，
            同一个文件被重复处理情况，通过重试和状态码不能有效解决，目前还没有达成统一方案。
			
(2) 
为了解决问题积极协调管软，lib，对象不同模块。
待提高：最终聚焦mds上，通过一个流程图或者4-5页解释清楚
抓住核心是什么，针对每个场景考虑清楚，如何解决的，解决方式是否考虑全面，是否还有其他方式代替和约束限制。



因为重复迁移场景，目前还没有达成统一方案

为了解决问题积极协调管软，lib，对象不同模块。
待提高：最终聚焦mds上，通过一个流程图或者4-5页解释清楚
抓住核心是什么，针对每个场景考虑清楚，如何解决的，解决方式是否考虑全面，是否还有其他方式代替和约束限制。



(1) 工作业绩：完善移动存力项目(GFS)多节点迁移和高可用方案，因为重复迁移场景，目前还没有达成统一方案。
(2)能力: 为了解决问题积极协调管软，lib，对象不同模块。
待提高：最终聚焦mds上，通过一个流程图或者4-5页解释清楚
抓住核心是什么，针对每个场景考虑清楚，如何解决的，解决方式是否考虑全面，是否还有其他方式代替和约束限制。
(3)态度：
期间：元数据管理在性能提示/故障处理/特性程有挑战完成事情,愿意投入时间和精力完成
待提高：抓住重点：从期望完成什么，验收标准什么入手，围绕目标不断探索，不够迭戈沟通





移动存力项目计划10月底完成GFS剩余功能。
包括：水位自迁移，对等体，双栈支持集成测试满足TR5要去
需要增加人手

(1) 工作业绩：完善移动存力项目(GFS)多节点迁移和高可用方案，因为重复迁移场景，目前还没有达成统一方案。
(2)能力: 为了解决问题积极协调管软，lib，对象不同模块。
待提高：最终聚焦mds上，通过一个流程图或者4-5页解释清楚
抓住核心是什么，针对每个场景考虑清楚，如何解决的，解决方式是否考虑全面，是否还有其他方式代替和约束限制。
(3)态度：
期间：元数据管理在性能提示/故障处理/特性程有挑战完成事情,愿意投入时间和精力完成
待提高：抓住重点：从期望完成什么，验收标准什么入手，围绕目标不断探索，不够迭戈沟通

工作业绩、能力和态度
(1)
(2)
(3)

(1) 工作业绩：
完善移动存力项目(GFS)多节点迁移和高可用方案，因为重复迁移场景，目前还没有达成统一方案。
(2)能力:
期间：积极协调管软，lib，对象不同模块。
待提高：最终聚焦mds上，通过一个流程图或者4-5页解释清楚
抓住核心是什么，针对每个场景考虑清楚，如何解决的，解决方式是否考虑全面，是否还有其他方式代替和约束限制。
(3)态度：
期间：元数据管理在性能提示/故障处理/特性程有挑战完成事情,愿意投入时间和精力完成
待提高：抓住重点：从期望完成什么，验收标准什么入手，围绕目标不断探索，不够迭戈沟通。

想要在分布式文件系统更近一步，
1. 不仅仅了解业务，更要了解业务最后抽象读写操作
  这样背后原理 例如目录分片，动态子树，掌握这些理论，
2. 提高视野，了解其他文件系统和其他产品 例如Lustre优秀地方
3. 端正态度，均衡工作,生活 投入。通过解决问题完成个人职业提升。
 




















抓住主要问题是什么，




最近三个月
全局文件系统移动存力项目
被考评人对自身在考评期内的工作业绩、能力和态度作出简要总结


工作业绩、
能力
态度



1. 工作业绩

移动存力（GFS）性能优化，单节点多线程跨域迁移完成后，在小文件迁移速度低于曙光，
主要在多节点迁移和高可用方案


移动存力（GFS）性能优化方案


1. 工作业绩
移动存力（GFS）项目性能优化
单节点并发迁移开发完成后，完善多节点迁移和高可用方案。
满足TR5,在部分场景上还没有达成统一方案。

2. 


移动存力期望目标


移动存力（GFS）


(1) 移动存力单节点并发迁移速度

(1) 移动并发迁移小文件迁移速度



(1) 性能优化指标 
  小文件并发迁移速度目前100+，期望300+，支持兼容各自故障
  目前在多节点迁移和高并发方案设计，因部分故障场景不兼容耗时2个月，
  




1. 工作业绩
移动存力（GFS）项目 项目性能优化
单节点并发迁移开发完成后，完善多节点迁移和高可用方案。
满足TR5,在部分场景上还没有达成统一方案。

c
3. 态度


--------------------
4. 
5.
6.
----------------------

 目录隔离方式虽然解决了不同节点处理不同任务，
 当进程，多线程 迁移同一个文件时候出现数据不一致情况，
 解决流程如下
 
 目录隔离方式虽然解决了不同节点处理不同任务，
 通过任务状态基方式 避免多进程，多线程导致出现数据不一致情况



任务状态定义：
(1) 不可见任务:该状态下任务,不能分配，不迁移。
(2) 已经分配任务：任务移动到待迁移目录
(3) 迁移中任务：迁移中记录文件当前剩余多少对象没有迁移，
                通过原子引用计数方式更新，支持多线程迁移。
				当剩余最后一个对象时候，标记文件被迁移远端集群
(4)迁移完成任务：标记该文件中任务迁移完成，需要最后一步更新元数据状态。
                 代表该文件元数据在近端集群，文件的真实数据迁移到远端集群
(5)迁移是文件/任务：迁移文件通过重新处理 变成状态(2) 重新迁移。


1）	文件迁移 当前集群分布式系统文件元数据保持不变，不影响用户日常访问，将一个分布式系统下文件写入到另外一个分布式系统文件，传输协议提供根据偏移量
同一个文件无论是否重复迁移都保证数据一致性，传输协议本身满足高并发 可扩展
只负责迁移文件，并不迁移文件元数据属性。需要对迁移文件元数据映射关系修改，才能保证不影响用户日常访问。



元数据扩展属性 标记文件已经迁移远端集群，
文件迁移前 通过查询该文件属性，避免重复迁移
在并发情况下，2个节点 同时查询同一个文件状态，都是未迁移状态。
出现同一个文件重复迁移，为解决这个问题流程调整如下：




(1) 任务分配 将任务写入到共享目录，完成任务状态从可见到已经分配
同一个文件被多多节点并发重复迁移，根据迁移文件属性最后在同一个元数据服务节点执行，元数据更新支持并发操作
	

原则上一个文件分配给一个节点迁移任务，
在网络等故障情况下导致文件重复分配多个节点执行，导致数据不一致。
基于任务状态基方式保证任务返回统一执行结果

1.	基于任务状态基方式实现高并发迁移
其中，对象存储服务，以其高可用性、可扩展性和数据持久性等特点，在分布式文件系统中得到了广泛应用。
然后分布式存储系统提供数据可靠持久化存储,但是在数据传输过程中，出现网络，节点，服务各种故障，高可用临重要挑战。

本方案基于原来分布式系统和s3协议，实现一个高并发，高可用迁移方案，应对服务遇见场景故障，保证数据一致性迁移。

 本发明提出基于数据生命周期管理实现分布式存储系统之间数据高可用迁移设计的一个方法
 
 
 本发明提出通过目录隔离方式实现集群之间文件并发迁移的一个方法
   
在高并发迁移
传统的文件系统通常局限于单个地域的数据管理，无法有效处理跨地域数据传输和同步的需求,全局文件系统，能够在不同地域之间实现智能的数据编织和管理。
本专利基于在原有对象存储协议(S3)基础上 解决海量小文和单个大文件传输效率低情况。
利用S3的多线程并发方式可以显著提高传输速度和效率，帮助应对大规模数据迁移的挑战,为全局文件系统提供更高效、可靠的跨区域数据传输解决方

1.	基于文件目录方式解耦任务发送和任务执行
1.	基于文件目录方式解耦任务发送和任务执行


任务发送:
将近端集群 不经常访问的文件分配给迁移节点，
任务执行：读取任务,将近端集群文件 迁移到远端集群过程。


不引入其他消息队列情况下，
利用分布式存储系统共享目录机制,为每个迁移任务进程建立不同目录存放任务
较低成本实现 任务发送，和任务处理解耦


基于任务状态基方式实现高并发迁移



本发明保护的使用s3协议应用在分布式存系统迁移数据 一种高并发的系统架构。

智能存储：利用对象存储协议(S3),近端集群冷数据 迁移到远端集群
////////////////
后端存储	受GFS管理的后端存储，可以为13000，也可以为第三方存储

近端集群：一种分布式文件系统，同时管理远端集群.
远端集群：第三方存储系统,存储近端集群冷数据。

全部执行 和分开执行都实现 分配跑2个

存力并发方案重新按如下思路分析：
1. 管软分发，以目录切分任务，明确具体的目录名路径等信息，不同节点backend扫描各自的目录，实现并发执行任务，支持多种策略：hash/轮询，其中hash说清楚根据什么hash；管软负责创建（生产者），目录负责存储（队列），backend定时消费；不需要管软通过命令通知到backend执行任务；
2.并发的核心问题是同一个文件并发迁移如何处理，1）文件迁移状态机，MDS加元数据控制；2）迁移失败不回滚，添加到失败任务文件再进行回滚；
3.高可用：基于1策略，不需要支持失败的backend将其任务分发给其他backend，backend何时起来何时重新扫描目录，backend当前有monitor自监控脚本，如果停了会自动拉起；
4.升级，如果按节点切分目录后，如何实现当前存力的升级？人为处理说明都行，比如等当前正在执行的都处理完，离线升级等等；
5.无需考虑自迁移，自迁移和这套思路不冲突；

第三次评审总结
1. 概要设计页数4-5页， 这个提示多次 从50M到120页 到30页，不自觉的 增加起来。
 这个情况自觉一定主要，一定是4到5页 【别人根本精力和时间看这个】 
 
 ---写太多，没有给出 什么场景，什么场景， 如何解决的，如何解决的。
 
 
 字体 截图 不统一 代码 
2. kafa故障，长连接故障，s3故障这样你不应该写--写时候犹豫了一下 最后填写的[和并发没有关系]
3. 你感觉 新增tick线程处理，tick周期结果 还是不行【实现上很难，感觉对对】
4. 自己的自测结果， 分析过程 写上不对【自己想清楚不写，暴露什么问题】
5.  按照思路 保证1000%正确吗？

----给谁看的----------

问题发生原因
引发什么场景问题
引发什么场景问题

----什么情况需要回顾 什么情况不需要回顾 这个说清楚。

怎么解决的，

那些解决不了问题是什么
同一个文件：
2个节点并发迁移，间隔时间短，
第一个失败回滚，第二个成功

第一个：
在setxattr执行过程过
第二个：开始迁移

无item_open_list占用
对xlock竞争，

--------------------------------------

在最后一个对象后，
重复释放caps core

多个节点并发情况
1. 成功，成功
2. 失败，成功 
3. 成功，失败 
4. 失败，失败 


任务状态记录inode中，
2个线程更新同一个地址。


2个方式
1.当文件被创建，删除时候 mds主动上报
2. 对账方式

这2个方式都没有统计文件访问次数。


2个节点并发迁移，间隔时间长
第一个：在setxattr执行过程过
第二个：开始迁移
第一个成功，第二个失败

第一个：在setxattr执行过程过，
第二个：在读写




存力并发方案重新按如下思路分析：
1. 管软分发，以目录切分任务，明确具体的目录名路径等信息，不同节点backend扫描各自的目录，实现并发执行任务，支持多种策略：hash/轮询，其中hash说清楚根据什么hash；管软负责创建（生产者），目录负责存储（队列），backend定时消费；不需要管软通过命令通知到backend执行任务；


2.并发的核心问题是同一个文件并发迁移如何处理，1）文件迁移状态机，MDS加元数据控制；2）迁移失败不回滚，添加到失败任务文件再进行回滚；


3.高可用：基于1策略，不需要支持失败的backend将其任务分发给其他backend，backend何时起来何时重新扫描目录，backend当前有monitor自监控脚本，如果停了会自动拉起；
4.升级，如果按节点切分目录后，如何实现当前存力的升级？人为处理说明都行，比如等当前正在执行的都处理完，离线升级等等；
5.无需考虑自迁移，自迁移和这套思路不冲突

////////////////////////////////////////



评审意见：
原因：
场景：【无法区分场景】
解决方式：
约束限制
无法解决问题
5页
高可用

格式 格式


-------
1. 自己推导到分析过程太多 隐藏问题。
   和解决不了方案。

2. 并发问题没有解决，发散到其他点子上。
其他无法内容不听写



方案能解决100%问题吗？

---------------------------





原因：这个


情况无法区分是单个文件单节点迁移，

并发迁移过程失败处理方案

1. 直接回滚，上报结果，让存力平台判断重试还是不重试
   适用条件：明确的错误
    1.write: 配置错误
	2. setxattr：文件大小被修改,文件不存在
	
   不能解决并发场景：一个成功，一个失败
   1. write阶段：远端集群s3 网络故障失败
   2. setxattr阶段 同一个文件被多个节点迁移
   原因：这个情况无法区分是单个文件单节点迁移，还是多节点迁移？
   
   优化方式
   1. 避免方式：接口失败，然后重试1次，减少s3服务重启，网络等故障影响。
   2. 重试后依然可能失败情况--见原因

2。针对具体错误码延迟回滚,其他直接回滚.
   方式1:元数据只记录文件是最终迁移结果--不可取
    根据元数据是否迁移完成,判断是否回滚,判断不准确
	不支持场景 存力重试 和迁移回滚冲突.
   
   方式2:元数据记录整个任务迁移状态,
   1. 在setxattr查询 ,如果不是setxattr阶段 说明有其他处理情况-直接返回具体错误
   2. 在write阶段查询,无法区分是当前write 还是其他阶段write--无法区分 
   3. 节点重启后,在重新迁移场景不好区分
   
3. 针对具体错误,不回滚重试
 新的影响:
  1 重试 也可能是失败,远端还是存在无法回滚文件.对比之前直回滚,增加新的影响
   
   



-----------------------------------------------------------------
rust-analyzer

1. 单节点执行时候 local不可用
2. 多节点处理

1. 当前任务分配失败
2. 部分文件迁移失败


1 目录隔离情况 不考虑
方法1：管软不负责任务发送，交给高可用节点。
完成任务


1. 元数据检索
2. 

不清楚项目方案是什么投入多次时间完成

通过开一次会议清楚方案是什么，投入多次时间完成
需要做那些事情？
1. 各种方案优缺点怎么分析
2. 全面分析各种情况

1. 挂载点不可用，写文件阻塞。
2. 自测出现，fuse读取任务core
   引发backend重启，加载历史任务迁移退出。
   
   
   



每次任务分配判断Backend健康状态
1. 增加集群负担
2. 这个情况是否模糊


任务分配后无迁移

1. 不进行重试
2. 目录隔离的直接放到各自目录。
3. 

1. 目录隔离方式，通知Backend失败情况不进程重试
2. 
1. 节点故障
2.  节点正常，迁移进程Backend异常

目录隔离方式分配，不进程重试
1. 按照分配方式任务移动目录
2. 不考虑backend是否接受任务情况

通知mds rank0 方式增加重试。



1.管理网卡，pulic网卡ifdown
2. kill管软故障
3.reboot

1 高可用方案设计
2 多节点方案设计
3.代码开发实现。


1. 分析各种故障类型，全面考虑异常。
2. 每个方案给出优缺点。
3. 代码开发。

昨天人员不够并没有对整个方案进行评审
只是针对3个故障类型进行讨论
1. 存力重试情况 章节2.1 满足 存力超时重试情况下，完成剩余文件迁移
2. 服务故障恢复后无法恢复情况 2.4.4。采取处理方案
3. 发送任务时候 服务节点异常处理 是否考虑节点是否存在。
4. 并没有对通过mds等其他存储进行详细讨论

下一步计划
1. 调查一下支持重复迁移可行性。
2. 完善并发思路和优缺点和不同故障处理。
避免方式
1. icfs dump 判断集群是否可用
2. 查询可用节点，不保证backend服务可用。

3.
1.管理网卡，pulic网卡ifdown
2. 管软故障 
避免方式
1. 管软产生任务完成时候rename任务
2. http引入去中心化token机制
   防止重复请求

1. icfs dump 判断集群是否可用
2. 查询可用节点，不保证backend服务可用。
3. 

1. 避免方式 迁移时候 单节点查重，
   多节点不支持
2. 支持重复迁移


管软重试，
同一个任务分配不同节点。
造成数据丢失
2 集群切,数据一 /mnt/fuse、

1. 挂载点短暂不可访问
2. 开发阶段：挂载点不可用
  需要手工重启nfs 
  或者手工删除历史任务


自测出现
nfs造创建一个文件，fuse读取失败
重复执行这个任务。
或者backend重启迁移任务

挂载点短暂不可用
或者永远不可用，
需要手工删除异常任务

1. 集群切换 /mnt/fuse 挂点不可用
2. gpair配置别修改
3. 自测出现代码问题
   
   
1.管理网卡，pulic网卡ifdown
2. 部分管软故障，reboot
 
 
 











 


   




1. 任务 占用内存评估
2. 管软与Backend 不与Backend 连接
   2者没有关系

1. MDS 周期性执行，根据umcomple表 撤销没有处理任务
2.  Backend与MDS之间有连接。针对不同故障情况有做判断。

1. 分级迁移内部的速度比跨域快
   
   
   


判断文件执行超时，文件积压数量 


1. 后台线程，增加管软负担
2.  判断一个服务不可用 通过进程 网络 节点存 超时 判断文件是否 方式 判断 过于复杂

1 增加ctdb 负担，影响更多业务
2. 同上
3. 增加一个服务，维护服务本身高可用



. 后台线程，增加管软负担
2.  判断一个服务不可用 通过进程 网络 节点存在方式比较复杂


1. 任务重新分配放到Backend完成，需要总线节点 保证Baackend 高可用

1. Backend不对外提供服务，让管软，ctdb提供虚拟ip 方式可是

1. 通过vip节点方式接受任务 单点
   Backend不对外提供服务，让管软，ctdb提供虚拟ip 不合适

2. 通过域名方式方式接受任务。Baackend是正常

1. 单独增加一个服务
2. 该服务可靠性自身保证形成单点
3.tick设置过大， mon 切换 ，都任务是主造成冲突 （引发）


1. 增加ctdb 负担，影响更多业务

1 .分配任务 处理任务 
2. 完成任务汇报状态 例如管软的中间件
3. 让管软监控任务状态，非判断进程 +目录文件积压方式








1. 每个Backend接受任务 支持
2. 撤回 选择一个节点执行


管软故障：
步骤1：临时任务不迁移，存力平台重试无影响
步骤2：
步骤3：
文件迁移，存力重试有并发问题
 
1. 不包含负载业务，可用通过脚本自动拉起监控
2. 让ctdb 保证节点和网络中正常

1 ctdb 保证 主节点 节点 和网络正常
2. 
1. 发送任务和撤销任务放被Keepalived 管统一管理
2. 避免管软通知期服务那个是最新节点。

1. 进程 不包含负载业务，故障后自动起来 自动拉起监控
2.  ctdb 保证节点 和网络正常。

1. 单独增加一个服务
2.该服务可靠性自身保证。不让ctdb接管。
形成单点
3. 不想s3 这个负载问题到用着管理







同一个节点负载高


负载高，
撤回部分任务，有重新分配回来。
参数控制
1. 设置合适的积压任务阈值
2. 调整回收任务个数n和分配任务m大小



backend重启加载和回收线程冲突
1. 回收线程设置[1backend,2backend]
2. 在回收之前在判断一次backend存活



1. 任务发送:移动对应目录，不考虑backend通知是否成功
2. 任务发送: 根据时间排序，连接5任务发同一个节点/随机
3. 任务处理：目录隔离无冲突。
4. 分配任务tick周期5秒，任务回收线程tick 80秒一次，不冲突


1. 轮询分配，根据时间排序，最近5个任务发送同一个节点
2. 调整tick周期，避免发送和回收任务线程冲突
3. 任务处理：目录隔离并发冲突



1.只要任务引入对应目录
 不考虑
 
任务发送:
1. 任务发送: 
  不考虑通知Backend 网络故障 和服务故障识别问题
  有回收任务线程处理
  
1.移入二级目录会后
2.不考虑通知Backend失败问题。



  
  

 
 

存力平台无限重试
同一批文件产生不同任务


1. 管软写临时任务故障--存力重试
2. rename后，管软故障不考虑




1. 不支持同一个文件被重复迁移
2. 不记录文件迁移过程。



1. 其其他线程在处理同一个文件无冲突
2. 兼顾 发送Kafa失败，迁移失败的文件


1. 任务发送:移动对应目录，不考虑backend通知是否成功
2. 任务发送: 根据时间排序，最近n个记录发送同一节查重。
2. 任务处理：目录隔离无冲突。
3. 分发tick周期5秒，任务回收线程tick 80秒一次，不冲突

  
1. 与任务发送线程无冲突
2. 与Backend任务执行无冲突
3. 与任务回收线程无冲突

1. Backend迁移无冲突 2 其他2个线程无冲突

1. 与其他2个线程无冲突
2. 与Backend无冲突
3. 与管软故障无冲突


1. 任务发送:移动对应目录,只通知backend一次不重试
2. 任务处理：目录隔离无冲突。

1. 任务发送:移动对应目录，不考虑backend通知是否成功
2. 任务处理：目录隔离无冲突。
3. 分发tick周期5秒，任务回收线程tick 80秒一次 不冲突


1 与s3长连接初始化建立好，不选择其他可用节点
2. setxattr不支持同一任务被重复处理
3. 迁移过程无法上报

】
1. 目录隔离backend处理无冲突
2. tick周期不一样，与回收线程无冲突12

1. tick周期不一样，与其他线程无冲突
2. 只要移入对应目录，发送命令失败不迁移其他节点， Backend直接处理冲突
3. Backend直接处理冲突

1. 分发


1. 迁移：目录隔离backend处理无冲突
2. 分发
1. 任务重新处理
2. 任务积压线程处理

1. 通过目录和限制同时执行隔离 解决重复处理问题
2. 一个任务可用在单节点重复执行。
3. 任务积压检测线程 撤回任务。


1. 通知kafa迁移结果可能多/少
2. s3 提供偏移量迁移，不解决
  偏移量之外文件变化。


1 与s3长连接初始化建立好，不选择其他可用节点
2. setxattr不支持同一任务被重复处理

1 与s3长连接初始化建立好，不选择其他可用节点
2. setxattr不支持同一任务被重复处理

1. s3确认是否心跳检测接口
2. 失败时针对错误码(待协商)重写连接其他节点
3. 执行过程数据丢

1. s3确认是否心跳检测接口
2. 失败时针对错误码(待协商)重写连接其他节点

3. 任务发送时候 根据时间排序 连续5个任务发送同一个节点
4. 不记录处理结果，只记录失败结果，等待下次处理。
 
 
 1. 多节点同时重复迁移
 2. 不存储迁移整个过程。

1. 目录隔离backend处理无冲突
2. tick周期不一样，与回收线程无冲突



1. 任务重新处理。还原中间结果
2. 任务积压线程处理

1. 通知Kafa记录

1.不记录中间结果，一个任务 500个文件，重新迁移。
2. 


打破信息差，把英文内容翻译中文
1. github最新热门项目，例如 ai各种开源工具
2. github开源产品背后设计理解，解决问题
3. 参考阮一峰的周刊，最近每周科技新闻

1. 经验分享：被面试官问的哑口无言(背后原理架构底层东西)
2. 经验分享：手撕红黑树

面试时候
1. 在线ide/白板手写2个算法，然后执行出结果
2. 系统设计绘制架构图，并3-5句话描述问题是什么

打破信息差，把英文内容翻译中文
1. github最新热门项目，例如 ai各种开源工具
2. github开源产品背后设计理解，解决问题
3. 参考阮一峰的周刊，最近每周科技新闻

看榜样怎么做的
1. 在外包，电信落后行业 
2. 最新行业发展：容器调度， 
3.创业公司人员：发明什么产品，解决什么问题

看榜样(非偶像)在做什么
1. 公司里厉害的人
2. 国内技术人分享
3. 国外技术人分享


本月
1. 稳定性: 
   1.1 完成丢文件和错误码原因定位。同一个问题，管软产生了重复请求，Backend迁移重复请求
   1.2 确定解决办法, Backend单节点排重，管软保证多个请求产生不同任务,
   1.3 放到多节点迁移一块实现。

2. 性能：
  2.1. 写速度移动统计完成，自测环境未完成。
  2.2  s3/lib不会优化，改为多节点并发迁移
  2.3  通过多节点迁移完成优化。

3 多节点迁移
 3.1 高可用设计 --无 
 3.3 多节点方案--无 
 ==============================================================
 
 
 1.高可用方案设计并评审通过
 2. 多节点方案设计并评审通过
 3. 功能实现

1. 迁移失败，回滚，然后存力重试
2.  迁移失败 延迟回回滚，回滚，然后存力重试

3 不回滚，自觉发起重试，存力发起重试


 
 ---------
1. 输出概要设计,并评审通过
2. 代码开发完成
3. 测试无bug


1. 概要设计，增加重试代替回滚方式 90%
2. 用虚拟机重新搭建一套环境
 
 setxattr 根据不同错误码不同处理
 1. 文件被修改---直接回滚
 2. 元数据被其他线程标记完成--- 迁移成功，不回滚
 3. 被占用情况---异步请求不重试，不回滚，文件重试
 4. 其他情况 同3
 

 
 
 

 
---------------------------------------
多节点任务
稳定性：
性能：
并发：
--------------------------------------------
1. 高可用方案实现20%，
   梳理解决问题是什么，绘制任务分发和执行流程图
2. 稳定性：重复文件迁移问题定位，
           已经通知管软修改，backend单节点查重处理
3. 配额测试支持。

任务状态
无分配
已经分配
转移其他节点任务


01--host1--ip1--process
02--host2--ip2--process
03--host3--ip3--process
..............
07--host7--ip7--process


1.阅读文件锁概要设计问，了解宽限期概念
2. 了解worm类型文件宽限期命令设置。 

keepalived

1. 新领导如何选举
2. 新的领导如何处理上个领导剩余热吻你
主要问题是：

管软:   任务分发
Backend：任务执行


将文件从一个集群迁移到另外一个集群。

存在什么问题

1.任务分配： 
   部分服务故障后，管软新分配任务/已经分配无法转移到可用节点上
   如果单个节点执行 服务不可用，多个节点，相关任务丢失。
2. 

期望结果：
1.任务不遗漏
2.迁移正确，




Backend 只负责任务执行，
在故障情况下，一个Backend故障了，请求发送到另外一个Backend上。
假设：新的Backend不去处理






-----------------------------------------
主要把移动存力 方案讨论清楚，能讨论一点是一点 
多讨论几次，吸纳其他人建议
多讨论几次，吸纳其他人建议。
讨论前提，综合考虑。

---------------------------------------------------------------
其他问题暂时不考虑一下。


好的，最后一周看能不能多投入一些，有困难的话跟立晓反馈下，让他跟移动再沟通沟通~~





curl -XPUT http://10.20.30.40:9200/_cluster/settings -d'
{
    "transient" : {
      "logger.discovery ": "WARN"
    }
}'

http://www.lvesu.com/blog/es/logging.html


http://www.lvesu.com/blog/es/logging.html



1. 丢数据问题确认管软在并发情况下遗漏任务。
2. 高可用方案设计10%，整理需求。


福布斯行为模型 提供方法 和原理，
怎么组合整出100个案例来，普通人可能需要这个。相互监督
你说出美好一天就具体

什么懒人，必须服务到家 提供方法，提供例子还不行，还是体验，监督 反馈







别的同学都睡觉你起床这么干什么，简直自欺欺人，你是整个班级，整个公司起床最晚那个人。


我30分钟床衣服


讨论结论：
1.文件内部并发采用现有的offset+len接口，不使用分片上传接口；
2.rename接口，S3实现目标目录不存在时创建；
3.采用每个迁移线程一个连接的方式，实现迁移对端多节点并发接收数据；
4.当前不实现多迁移任务并发，后面实测下迁移效果；




rename


3月产生并发迁移优化思路，4月份实现一篇。


1. 容易题不丢分，先吃小甜点+1分，增加学习动力
  std::move()实现原理 为什么
  为什么支持传入的是左值还是右值这2个参数是&&原因吗
  为什么返回的都是右值引用，是static_cast功劳吗？
  了解rust 用引用 生命周期用法
  完全是程序员思维。不管什么raft，什么rockdb，自己看不懂内容
  
  
  如果 T 是一个左值引用类型（如 int&），
  T&& 将折叠为 T&；
  如果 T 是一个右值引用类型（如 int&&），T&& 将折叠为 T。
  
  
  商家最终解释权，
  

从样板到最后实例化中间还有过程 
这个编译器发挥作用了



买家秀

1. 构思文件并发迁移专利内容，本月无实现，下月开始实现一篇，
2. 为专利专员讲解上个专利内容，完成节点审批。
s

1. Backend在重复迁移,ifdown网卡等情况出现放caps会core验证。

1. Backend什么情况出现迁移出现core验证
  s 单节点重复迁移查重处
2.

1.Backend在各种故障情况下服务是否core验证
 a:单节点重复迁导致重复释放caps
 b：gpair配置变动 
 c：ifdown网卡--出现过1次，待还原原因a
 
2.并发不一致原因分析
 有业务读写，client caps 没有调整want=-1情况
 导致setxattr失败
3. 2个实现方案对比
  方案1：元数据增加任务状态，判断不可用，
  方案2：根据错误码判断回滚不回滚改为重新迁移一次
4.整理HA方案

  
  
1.济南IT现场core问题跟踪
无法远程支持，在开发环境构造同样环境查看core文件
 快照为null断言，不能规避方式解决，
待实现：构造同样数据，还原core场景。

2. 机器上架